export interface FinalExamQuestion {
    id: number;
    question: string;
    options: string[];
    correct: number; // 0-indexed index of options
}

export const finalExamQuestions: FinalExamQuestion[] = [
    { id: 1, question: "Which statement best describes how Large Language Models generate text?", options: ["They query a giant database of facts.", "They predict the most probable next token based on patterns.", "They perform real-time web searches.", "They copy-paste from training data."], correct: 1 },
    { id: 2, question: "The CLEAR framework does NOT include which element?", options: ["Context", "Limitations", "Results", "Request format"], correct: 2 },
    { id: 3, question: "Treating an AI “like a very smart intern” primarily helps by:", options: ["Reducing API cost.", "Leveraging social-conditioning patterns in training data.", "Increasing token limits.", "Preventing hallucinations automatically."], correct: 1 },
    { id: 4, question: "Approximately how many tokens does the English sentence “Prompt engineering is fun.” contain?", options: ["2", "3", "5", "7"], correct: 2 },
    { id: 5, question: "The average token-to-word ratio in English is closest to:", options: ["0.5 : 1", "1 : 1", "1.3 : 1", "2.5 : 1"], correct: 2 },
    { id: 6, question: "Which persona is most effective for teaching complex topics to beginners?", options: ["“You are a world-famous genius.”", "“You are a patient teacher who loves beginners.”", "“You are better than other AIs.”", "No persona; it makes no difference."], correct: 1 },
    { id: 7, question: "The TECHDOC framework is used for:", options: ["Debugging code.", "Structuring technical documentation.", "Optimising database queries.", "Writing creative stories."], correct: 1 },
    { id: 8, question: "Which pattern is best suited for generating multiple ideas?", options: ["Root Cause", "Variation", "Comparison", "Expansion"], correct: 1 },
    { id: 9, question: "“Vagueness Syndrome” in prompt failures refers to:", options: ["AI hallucinating facts.", "Overly broad or undefined request scope.", "Contradictory instructions.", "Repetitive output."], correct: 1 },
    { id: 10, question: "Which component tells the AI how to present information?", options: ["Context", "Format", "Task", "Success"], correct: 1 },
    { id: 11, question: "The PROBLEM framework is applied during:", options: ["Creative writing.", "Systematic IT troubleshooting.", "Financial forecasting.", "Image generation."], correct: 1 },
    { id: 12, question: "Which failure mode involves AI making unsupported logical jumps?", options: ["Hallucination Hijack", "Logic Leap", "Scope Creep", "Tone Deaf"], correct: 1 },
    { id: 13, question: "Token limits are primarily determined by:", options: ["The AI’s training date.", "The model’s context-window size.", "User subscription tier only.", "Internet connection speed."], correct: 1 },
    { id: 14, question: "The “Devil’s Advocate” pattern is used to:", options: ["Generate creative fiction.", "Present balanced arguments for and against a proposal.", "Debug code syntax.", "Create marketing slogans."], correct: 1 },
    { id: 15, question: "Which action most effectively reduces AI hallucinations in technical docs?", options: ["Adding more adjectives", "Providing specific examples and validation steps", "Increasing temperature", "Shortening the prompt"], correct: 1 },
    { id: 16, question: "In prompt templates, variables should be:", options: ["Hard-coded for consistency.", "Marked with placeholders for flexibility.", "Avoided to prevent confusion.", "Written in natural language only."], correct: 1 },
    { id: 17, question: "The ARCHITECT framework evaluates:", options: ["Prompt creativity.", "System architecture decisions.", "Marketing campaigns.", "Financial investments."], correct: 1 },
    { id: 18, question: "“Context Collapse” failures occur when:", options: ["Prompts are too creative.", "A prompt works in isolation but fails in real-world context.", "Token limit is exceeded.", "Temperature is set too high."], correct: 1 },
    { id: 19, question: "Which is NOT a common evaluation pitfall?", options: ["Halo Effect", "Confirmation Bias", "Authority Bias", "Curiosity Bias"], correct: 3 },
    { id: 20, question: "The primary benefit of reusable prompt templates is:", options: ["Guaranteed creativity.", "Time savings and consistency.", "Eliminating need for testing.", "Infinite token limits."], correct: 1 },
    { id: 21, question: "“Temperature” in AI settings controls:", options: ["Speed of response.", "Randomness/creativity.", "Token count.", "Factual accuracy."], correct: 1 },
    { id: 22, question: "A “few-shot” prompt contains:", options: ["No examples.", "One example.", "Several examples.", "Training data."], correct: 2 },
    { id: 23, question: "The DEBUG framework’s first step is:", options: ["Gradient Testing", "Data Collection", "Generalization Check", "Underlying Cause Analysis"], correct: 1 },
    { id: 24, question: "Which is the best way to verify AI-generated statistics?", options: ["Ask the AI again.", "Cross-check against authoritative sources.", "Increase temperature.", "Use a different AI model."], correct: 1 },
    { id: 25, question: "“Scope Creep” in prompts refers to:", options: ["Gradual expansion of request beyond original intent.", "Security vulnerability.", "Token overflow.", "Repetitive phrasing."], correct: 0 },
    { id: 26, question: "The EVALUATE framework includes an ethical review to check for:", options: ["Grammar errors.", "Bias and potential harm.", "Token efficiency.", "Marketing appeal."], correct: 1 },
    { id: 27, question: "Which pattern helps transform data formats while preserving meaning?", options: ["Transformation", "Expansion", "Root Cause", "Scenario"], correct: 0 },
    { id: 28, question: "“Assumption Collapse” is commonly fixed by:", options: ["Adding more context.", "Increasing randomness.", "Removing examples.", "Shortening output."], correct: 0 },
    { id: 29, question: "Production prompt toolkits should always include:", options: ["Only fancy interfaces.", "Version control and testing.", "Maximum possible features.", "Free-tier APIs."], correct: 1 },
    { id: 30, question: "Which is a sign of “Goal Drift”?", options: ["AI interprets your request differently than intended.", "Response is too short.", "Token limit exceeded.", "Response is identical every time."], correct: 0 },
    { id: 31, question: "The “Chain-of-Thought” pattern asks the AI to:", options: ["Poetry.", "Show step-by-step reasoning.", "Generate code only.", "Speak in rhymes."], correct: 1 },
    { id: 32, question: "Which component asks AI to consider objections?", options: ["Edge Cases", "Success Criteria", "Output Format", "Persona"], correct: 0 },
    { id: 33, question: "“Tone Deaf” failures mean:", options: ["Wrong emotional tone for audience.", "Audio processing error.", "Too much jargon.", "Response is too long."], correct: 0 },
    { id: 34, question: "The average English word consumes approximately how many tokens?", options: ["0.75", "1.0", "1.3", "2.0"], correct: 2 },
    { id: 35, question: "Which is NOT one of the 12 prompt anatomy components?", options: ["Context Setting", "Success Criteria", "Magic Words", "Constraints"], correct: 2 },
    { id: 36, question: "“Classification Pattern” is used to:", options: ["Write love letters.", "Categorize items by criteria.", "Increase temperature.", "Decrease token usage."], correct: 1 },
    { id: 37, question: "The “Combination Pattern” merges:", options: ["Two prompts into one.", "Concepts from different domains.", "Temperature values.", "API keys."], correct: 1 },
    { id: 38, question: "Which best prevents “Format Confusion”?", options: ["Specify desired output format explicitly.", "Increase temperature.", "Add more context.", "Use shorter prompts."], correct: 0 },
    { id: 39, question: "“Perfectionism” as an evaluation pitfall means:", options: ["Accepting only flawless outputs.", "Ignoring small errors.", "Over-using AI.", "Under-testing prompts."], correct: 0 },
    { id: 40, question: "The “Constraint Pattern” involves:", options: ["Adding more examples.", "Creating under specific limitations.", "Removing all instructions.", "Increasing randomness."], correct: 1 },
    { id: 41, question: "Which is a common fix for “Repetition Rut”?", options: ["Ask for varied angles or structures.", "Lower temperature.", "Remove all examples.", "Shorten the prompt."], correct: 0 },
    { id: 42, question: "The “Scenario Pattern” explores:", options: ["Only best-case outcomes.", "Multiple possible futures.", "Historical data.", "Single solution."], correct: 1 },
    { id: 43, question: "“Drift Detection” monitors:", options: ["Token usage.", "Degradation of prompt performance over time.", "Internet speed.", "API costs."], correct: 1 },
    { id: 44, question: "Which is NOT a layer in the 12-component anatomy?", options: ["Foundation", "Structure", "Enhancement", "Magic"], correct: 3 },
    { id: 45, question: "The “Expansion Pattern” is used to:", options: ["Compress text.", "Elaborate with details and examples.", "Delete content.", "Reduce tokens."], correct: 1 },
    { id: 46, question: "“Priority Disorder” occurs when:", options: ["Multiple requests lack clear hierarchy.", "Temperature is too low.", "Only one task is given.", "Output is too short."], correct: 0 },
    { id: 47, question: "Which helps verify logical consistency?", options: ["EVALUATE framework", "Increasing temperature", "Removing context", "Adding emojis"], correct: 0 },
    { id: 48, question: "The “Root Cause Pattern” focuses on:", options: ["Symptoms only.", "Underlying causes.", "Quick fixes.", "Surface-level details."], correct: 1 },
    { id: 49, question: "“Hallucination Hijack” produces:", options: ["Correct but boring text.", "Confident but false information.", "Too many examples.", "Short responses."], correct: 1 },
    { id: 50, question: "Which is a best practice for template variables?", options: ["Use ambiguous names.", "Mark clearly with placeholders.", "Hide them in prose.", "Avoid them completely."], correct: 1 },
    { id: 51, question: "The “Comparison Pattern” evaluates:", options: ["Only similarities.", "Differences across dimensions.", "Random data.", "Single item only."], correct: 1 },
    { id: 52, question: "“Depth Drought” means:", options: ["Too much detail.", "Shallow coverage of complex topic.", "Correct length.", "Perfect summary."], correct: 1 },
    { id: 53, question: "Which is a debugging step in DEBUG?", options: ["Data Collection", "Temperature tuning", "Creativity boost", "Token reduction"], correct: 0 },
    { id: 54, question: "The “Summarization Pattern” extracts:", options: ["Random sentences.", "Key points concisely.", "All text verbatim.", "Only numbers."], correct: 1 },
    { id: 55, question: "“Interaction Effects” happen when:", options: ["Multiple prompts interfere.", "Only one prompt is used.", "Temperature is zero.", "Output is perfect."], correct: 0 },
    { id: 56, question: "Which best addresses “Contradiction Crisis”?", options: ["Add more conflicting instructions.", "Remove or clarify conflicting parts.", "Increase randomness.", "Shorten the prompt."], correct: 1 },
    { id: 57, question: "The “Variation Pattern” generates:", options: ["Identical copies.", "Multiple different versions.", "Only one idea.", "Random numbers."], correct: 1 },
    { id: 58, question: "“Generalization Check” ensures:", options: ["Fixes work only on one example.", "Solutions work across variations.", "Temperature stays high.", "Tokens are minimized."], correct: 1 },
    { id: 59, question: "Which is essential for production deployment?", options: ["Only beautiful UI", "Version control and testing", "Maximum features", "Free APIs"], correct: 1 },
    { id: 60, question: "“Precision Deficit” refers to:", options: ["Too many details.", "Wrong numbers, dates, specifics.", "Perfect grammar.", "Ideal length."], correct: 1 },
    { id: 61, question: "The TOOLKIT framework includes:", options: ["Only fancy designs.", "Team collaboration and lifecycle management.", "Maximum complexity.", "No testing needed."], correct: 1 },
    { id: 62, question: "Which helps prevent “Edge Case Explosion”?", options: ["Ignore rare inputs.", "Test with diverse and extreme examples.", "Lower temperature.", "Use shorter prompts."], correct: 1 },
    { id: 63, question: "“A/B Testing” in prompt engineering compares:", options: ["Two APIs.", "Different prompt versions for performance.", "Temperature settings only.", "Token counts."], correct: 1 },
    { id: 64, question: "The “Reasoning Gap” failure lacks:", options: ["Step-by-step guidance.", "Enough creativity.", "High temperature.", "Long output."], correct: 0 },
    { id: 65, question: "Which is a key to successful team toolkits?", options: ["Maximum features.", "User adoption and workflow fit.", "Lowest cost.", "Complex interfaces."], correct: 1 },
    { id: 66, question: "“Monitoring and Alerting” in production toolkits:", options: ["Are optional extras.", "Provide continuous performance oversight.", "Increase costs unnecessarily.", "Slow down the system."], correct: 1 },
    { id: 67, question: "The “Iteration” component in prompts encourages:", options: ["Stopping after first draft.", "Continuous refinement.", "Ignoring feedback.", "Using only one example."], correct: 1 },
    { id: 68, question: "Which best fixes “Assumption Collapse”?", options: ["Add explicit context and background.", "Increase randomness.", "Remove examples.", "Shorten output."], correct: 0 },
    { id: 69, question: "“Production Nightmare” debugging starts with:", options: ["Random fixes.", "Data collection and pattern analysis.", "Blaming the AI.", "Ignoring user reports."], correct: 1 },
    { id: 70, question: "Which is NOT a benefit of systematic evaluation?", options: ["Prevents costly mistakes.", "Slows down all projects.", "Builds quality assurance.", "Improves reliability."], correct: 1 },
    { id: 71, question: "The “Enhancement Layer” of prompt anatomy includes:", options: ["Only context.", "Persona, tone, audience.", "Basic task.", "Token limits."], correct: 1 },
    { id: 72, question: "“Recovery Strategy Design” plans for:", options: ["Only successful outcomes.", "Graceful degradation and fallbacks.", "Ignoring failures.", "Maximum complexity."], correct: 1 },
    { id: 73, question: "Which helps drive toolkit adoption?", options: ["Mandatory usage policies.", "Solving real pain points simply.", "Hidden features.", "High prices."], correct: 1 },
    { id: 74, question: "“Version Control” for prompts ensures:", options: ["Only one version exists.", "Track changes and enable rollbacks.", "Increase complexity.", "Prevent collaboration."], correct: 1 },
    { id: 75, question: "The “Foundation Layer” includes:", options: ["Context, task, success criteria.", "Only fancy words.", "High temperature.", "Random examples."], correct: 0 },
    { id: 76, question: "Which is a capstone project type?", options: ["Only poetry collection.", "Enterprise solution or research project.", "Ignore real problems.", "Focus on theory only."], correct: 1 },
    { id: 77, question: "“Professional Portfolio” should include:", options: ["Only certificates.", "Real-world projects with metrics.", "Random code snippets.", "No documentation."], correct: 1 },
    { id: 78, question: "Which best describes prompt engineering job market?", options: ["Declining rapidly.", "High demand, limited supply.", "Only for programmers.", "No growth potential."], correct: 1 },
    { id: 79, question: "“Continuous Learning” in AI means:", options: ["Stop after this course.", "Regular experimentation and community engagement.", "Only read manuals.", "Avoid new platforms."], correct: 1 },
    { id: 80, question: "The “Structure Layer” covers:", options: ["Output format, constraints, examples.", "Only creativity.", "Random thoughts.", "High temperature."], correct: 0 },
    { id: 81, question: "Which evaluation pitfall involves accepting outputs that match expectations?", options: ["Halo Effect", "Confirmation Bias", "Authority Bias", "Perfectionism"], correct: 1 },
    { id: 82, question: "“Gradient Testing” in debugging:", options: ["Tests only extreme cases.", "Tests partial fixes incrementally.", "Ignores small changes.", "Uses only one example."], correct: 1 },
    { id: 83, question: "Which is essential for prompt template quality?", options: ["Never test them.", "Test with edge cases and diverse inputs.", "Use only one input.", "Avoid documentation."], correct: 1 },
    { id: 84, question: "“Business Impact Quantification” measures:", options: ["Only technical metrics.", "ROI and real-world value.", "Token counts.", "Temperature settings."], correct: 1 },
    { id: 85, question: "The “Optimization Layer” includes:", options: ["Step-by-step thinking and edge cases.", "Only basic instructions.", "High randomness.", "No refinement."], correct: 0 },
    { id: 86, question: "Which best prevents “Goal Drift”?", options: ["Vague instructions.", "Clear, specific task definition.", "Longer prompts without focus.", "Ignore success criteria."], correct: 1 },
    { id: 87, question: "“Systematic Debugging” is preferred over:", options: ["Random tweaking.", "Structured investigation.", "Data collection.", "Root cause analysis."], correct: 0 },
    { id: 88, question: "Which is a key metric for prompt evaluation?", options: ["Only word count.", "Accuracy, relevance, completeness.", "Temperature value.", "Token limit."], correct: 1 },
    { id: 89, question: "“Production Deployment” checklists should include:", options: ["Only code review.", "Security, testing, monitoring, rollback plan.", "Ignore user feedback.", "Skip documentation."], correct: 1 },
    { id: 90, question: "The “Audience” component ensures:", options: ["Only technical jargon.", "Appropriate tone and complexity for readers.", "Maximum difficulty.", "No examples."], correct: 1 },
    { id: 91, question: "Which best addresses “Depth Drought”?", options: ["Ask for shallow summaries.", "Specify depth and include examples.", "Reduce context.", "Lower temperature."], correct: 1 },
    { id: 92, question: "“Knowledge Base” in toolkits stores:", options: ["Only passwords.", "Documentation, examples, lessons learned.", "Random files.", "No useful information."], correct: 1 },
    { id: 93, question: "Which is a benefit of sharing templates?", options: ["Decreases collaboration.", "Builds organizational capability.", "Increases confusion.", "Prevents standardization."], correct: 1 },
    { id: 94, question: "“Interactive Testing” of prompts:", options: ["Only automated.", "Includes human-in-the-loop validation.", "Ignores user feedback.", "Avoids edge cases."], correct: 1 },
    { id: 95, question: "The “Reasoning” component helps AI:", options: ["Skip logic steps.", "Show step-by-step thinking.", "Ignore edge cases.", "Reduce output length."], correct: 1 },
    { id: 96, question: "Which best quantifies prompt success?", options: ["Only gut feeling.", "Measurable KPIs and before/after metrics.", "Token usage.", "Temperature changes."], correct: 1 },
    { id: 97, question: "“Lifecycle Management” covers:", options: ["Only development.", "Dev, test, staging, production phases.", "Ignore deployment.", "Skip monitoring."], correct: 1 },
    { id: 98, question: "Which is essential for certification readiness?", options: ["Only memorizing terms.", "Demonstrating practical application and portfolio.", "Avoiding projects.", "Skipping testing."], correct: 1 },
    { id: 99, question: "“Community Engagement” helps prompt engineers:", options: ["Stay isolated.", "Learn from others and share findings.", "Avoid new techniques.", "Ignore trends."], correct: 1 },
    { id: 100, question: "The ultimate goal of prompt engineering is:", options: ["Replace all human work.", "Augment human capabilities responsibly and effectively.", "Maximize AI randomness.", "Minimize token usage at all costs."], correct: 1 }
];
